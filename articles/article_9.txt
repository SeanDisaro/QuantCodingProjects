Nvidia (NASDAQ:NVDA) closed out 2025 by splashing out on what could prove to be a significant deal. On December 24, the chip giant announced a non-exclusive licensing agreement with Groq, an AI inference chip company founded by former Google TPU engineers, covering its inference technology. The deal is reportedly valued at $20 billion, with Groq expected to generate $1.4 billion in revenue in 2026.But the deal involves more than just the tech. As part of the transaction, Groq founder Jonathan Ross, President Sunny Madra, and additional team members will join Nvidia to support the advancement and scaling of the licensed tech. Ross, who will serve as Nvidia’s Chief Software Architect, previously helped build and scale Google’s TPU before co-founding Groq with other Google engineers in 2016. Groq will remain an independent company, and its GroqCloud developer platform, which provides API access to Groq’s LPUs, will keep on operating without interruption. Cowen analyst Joshua Buchalter sees the move as potentially transformative. In his view, Nvidia isn’t just adding another tool to its arsenal – it’s opening the door to a different way of thinking about AI computing altogether.
		“With the deal,” says the analyst, “NVIDIA is embracing a fundamentally different processing architecture that we believe will eventually be integrated into its roadmap.”Groq’s architecture differs fundamentally from GPUs. Its LPU (language processing unit) processors use deterministic spatial dataflow, executing operations in a fixed sequence. As a “classic example,” Buchalter compares the two architectures to factories: an LPU is like a high-speed, purpose-built assembly line, while a GPU resembles a busy factory where a manager gives tasks to workers.An LPU is designed to make AI inference faster, more consistent, and more energy-efficient. To do this, it relies on a smart compiler that carefully plans exactly when and where each calculation happens and how data flows through the chip. In simple terms, the chip itself stays simple, while the software does all the hard work.Groq’s LPUs are built specifically for AI inference, with Buchalter believing they are not aimed at the training market. The analyst thinks that Nvidia’s adoption of an inference-focused chip – and a new architecture – highlights how “large and mature” low-latency inference has become. Previously, AI infrastructure investments tended to prioritize training, under the logic that training chips would later serve for inference.“This is unsurprising as the industry has indicated an increasing portion of revenue coming from inference,” Buchalter further said, “but NVIDIA’s licensing deal with Groq likely signals the inference market has scaled to the point where inference-only procurement is an increasingly material portion of the market.”
		To this end, Buchalter sticks with a Buy rating on NVDA shares, assigning a $235 price target that implies ~24% upside over the next 12 months. (To watch Buchalter’s track record, click here)Meanwhile, the broader analyst community is even more optimistic. The Street’s average price target of $262.79 suggests 39% upside, and with 39 Buys against just one Hold and one Sell, Nvidia carries a Strong Buy consensus rating. (See NVDA stock analysis)To find good ideas for AI stocks trading at attractive valuations, visit TipRanks’ Best Stocks to Buy, a tool that unites all of TipRanks’ equity insights.Disclaimer: The opinions expressed in this article are solely those of the featured analyst. The content is intended to be used for informational purposes only. It is very important to do your own analysis before making any investment.Disclaimer & DisclosureReport an IssueCopyright © 2025
    Insider Inc and finanzen.net GmbH (Imprint). All rights reserved.
    Registration on or use of this site constitutes acceptance of our Terms of Service and Privacy Policy.